## Visual-Language Pretraining Paper List

| Id | Title | Conference | Link | Code |
|:--:| ----- | :--: | ---- | ---- |
| 1  | UNITER: UNiversal Image-TExt Representation Learning | ECCV 2020 |[1909.11740](https://arxiv.org/abs/1909.11740)|[UNITER](https://github.com/ChenRocks/UNITER)|
| 2  | Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks | ECCV 2020 |[2004.06165](https://arxiv.org/abs/2004.06165)|[Oscar](https://github.com/microsoft/Oscar)|
| 3  | Large-Scale Adversarial Training for Vision-and-Language Representation Learning | NeurIPS 2020 Spotlight |[2006.06195](https://arxiv.org/abs/2006.06195) |[VILLA](https://github.com/zhegan27/VILLA)|
| 4 | ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through Scene Graph | AAAI 2020 |[2006.16934](https://arxiv.org/abs/2006.16934)|[ERNIE-ViL](https://github.com/Muennighoff/vilio/tree/master/ernie-vil)|
| 5  | UNIMO: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning | ACL 2021 |[2012.15409](https://arxiv.org/abs/2012.15409)|[UNIMO](https://github.com/weili-baidu/UNIMO)|
| 6  | InterBERT: Vision-and-Language Interaction for Multi-modal Pretraining | |[2003.13198](https://arxiv.org/abs/2003.14198)| |
| 7  | M6: A Chinese Multimodal Pretrainer | |[2103.00823](https://arxiv.org/abs/2103.00823)| |
| 8  | ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision | ICML 2021 |[2102.03334](https://arxiv.org/abs/2102.03334)|[ViLT](https://github.com/dandelin/ViLT)|
| 9  | VinVL: Revisiting Visual Representations in Vision-Language Models | CVPR 2021 |[2101.00529](https://arxiv.org/abs/2101.00529)|[VinVL](https://github.com/pzzhang/VinVL)|






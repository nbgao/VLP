## Visual-Language Pretraining Paper List

| Id | Title | Conference | Link | Code |
|:--:| ----- | :--: | ---- | ---- |
| 1  | LXMERT: Learning Cross-Modality Encoder Representations from Transformers | EMNLP 2019 |[1908.07490](https://arxiv.org/abs/1908.07490)|[LXMERT](https://github.com/airsplay/lxmert)|
| 2  | UNITER: UNiversal Image-TExt Representation Learning | ECCV 2020 |[1909.11740](https://arxiv.org/abs/1909.11740)|[UNITER](https://github.com/ChenRocks/UNITER)|
| 3  | Pixel-BERT: Aligning Image Pixels with Text by Deep Multi-Modal Transformers |  | [2004.00849](https://arxiv.org/abs/2004.00849) ||
| 4  | Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks | ECCV 2020 |[2004.06165](https://arxiv.org/abs/2004.06165)|[Oscar](https://github.com/microsoft/Oscar)|
| 5  | Large-Scale Adversarial Training for Vision-and-Language Representation Learning | NeurIPS 2020 Spotlight |[2006.06195](https://arxiv.org/abs/2006.06195) |[VILLA](https://github.com/zhegan27/VILLA)|
| 6 | ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through Scene Graph | AAAI 2020 |[2006.16934](https://arxiv.org/abs/2006.16934)|[ERNIE-ViL](https://github.com/Muennighoff/vilio/tree/master/ernie-vil)|
| 7  | UNIMO: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning | ACL 2021 |[2012.15409](https://arxiv.org/abs/2012.15409)|[UNIMO](https://github.com/PaddlePaddle/Research/tree/master/NLP/UNIMO)|
| 8  | InterBERT: Vision-and-Language Interaction for Multi-modal Pretraining | |[2003.13198](https://arxiv.org/abs/2003.14198)| |
| 9  | M6: A Chinese Multimodal Pretrainer | |[2103.00823](https://arxiv.org/abs/2103.00823)| |
| 10  | ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision | ICML 2021 |[2102.03334](https://arxiv.org/abs/2102.03334)|[ViLT](https://github.com/dandelin/ViLT)|
| 11  | VinVL: Revisiting Visual Representations in Vision-Language Models | CVPR 2021 |[2101.00529](https://arxiv.org/abs/2101.00529)|[VinVL](https://github.com/pzzhang/VinVL)|
| 12 | Seeing Out of tHe bOx: End-to-End Pre-training for Vision-Language Representation Learning | CVPR 2021 | [2104.03135](https://arxiv.org/abs/2104.03135) | [SOHO](https://github.com/researchmm/soho)|
| 13 | StructVBERTï¼šVisual-Linguistic Pre-training for Visual Question Answering | VQA2021 1st |  | [StructVBERT](https://github.com/alibaba/AliceMind/tree/main/StructVBERT)|




